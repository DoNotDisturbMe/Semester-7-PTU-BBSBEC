{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L2hVENXsE9a",
        "outputId": "a10f8fff-7b5f-4c97-f294-e4bb721ccb5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 4)                 12        \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 10        \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22 (88.00 Byte)\n",
            "Trainable params: 22 (88.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-8a2f8af09560>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x = np.array([[2,2], [2,4], [2.5], [4,5], [4,8], [4,6]])\n"
          ]
        }
      ],
      "source": [
        "# Creating a basic network and analyze its performance\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Use numpy arrays to store inputs (x) and outputs (y):\n",
        "\n",
        "x = np.array([[2,2], [2,4], [2.5], [4,5], [4,8], [4,6]])\n",
        "\n",
        "y = np.array([[2], [2], [4], [5], [6], [8]])\n",
        "\n",
        "# Define the network model and its arguments.\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Dense(4, input_shape=(2,)))\n",
        "model.add(Activation('linear'))\n",
        "\n",
        "model.add(Dense(2))\n",
        "\n",
        "model.add(Activation('linear'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy the Confusion matrix and simulate for Overfitting\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a simple feedforward neural network\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_dim=4),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=0)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = [tf.argmax(x).numpy() for x in y_pred]\n",
        "\n",
        "# Generate a confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Simulate overfitting by training for more epochs\n",
        "overfit_model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_dim=4),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "overfit_model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data for too many epochs\n",
        "overfit_model.fit(X_train, y_train, epochs=1000, batch_size=32, verbose=0)\n",
        "\n",
        "# Evaluate the overfit model on the test data\n",
        "y_pred_overfit = overfit_model.predict(X_test)\n",
        "y_pred_overfit_classes = [tf.argmax(x).numpy() for x in y_pred_overfit]\n",
        "\n",
        "# Generate a confusion matrix for the overfit model\n",
        "conf_matrix_overfit = confusion_matrix(y_test, y_pred_overfit_classes)\n",
        "print(\"\\nConfusion Matrix for Overfit Model:\")\n",
        "print(conf_matrix_overfit)\n",
        "\n",
        "# Plot confusion matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].matshow(conf_matrix, cmap=plt.cm.Blues, interpolation='nearest')\n",
        "axes[0].set_title('Confusion Matrix (Normal)')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('True')\n",
        "\n",
        "axes[1].matshow(conf_matrix_overfit, cmap=plt.cm.Blues, interpolation='nearest')\n",
        "axes[1].set_title('Confusion Matrix (Overfit)')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('True')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "NiTkOcZPuE8v",
        "outputId": "37d8555d-9b04-475e-d5ca-3bb1bcd5a799"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 51ms/step\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  8  1]\n",
            " [ 0  0 11]]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "\n",
            "Confusion Matrix for Overfit Model:\n",
            "[[10  0  0]\n",
            " [ 0  8  1]\n",
            " [ 0  0 11]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing a neural network\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Create a simple feedforward neural network\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Generate a graphical representation of the network\n",
        "plot_model(model, to_file='neural_network.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# If you want to display the network architecture in Jupyter Notebook\n",
        "from IPython.display import Image\n",
        "Image(\"neural_network.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "caB39a7KutGY",
        "outputId": "4dfdef4a-5e4a-4943-e0fd-657dc0ac8325"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo: Object Detection with pre-trained RetinaNet with Keras\n",
        "# https://keras.io/examples/vision/retinanet/\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "url = \"https://github.com/srihari-humbarwadi/datasets/releases/download/v0.1.0/data.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"data.zip\")\n",
        "keras.utils.get_file(filename, url)\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(\"data.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"./\")\n",
        "def swap_xy(boxes):\n",
        "    \"\"\"Swaps order the of x and y coordinates of the boxes.\n",
        "\n",
        "    Arguments:\n",
        "      boxes: A tensor with shape `(num_boxes, 4)` representing bounding boxes.\n",
        "\n",
        "    Returns:\n",
        "      swapped boxes with shape same as that of boxes.\n",
        "    \"\"\"\n",
        "    return tf.stack([boxes[:, 1], boxes[:, 0], boxes[:, 3], boxes[:, 2]], axis=-1)\n",
        "\n",
        "\n",
        "def convert_to_xywh(boxes):\n",
        "    \"\"\"Changes the box format to center, width and height.\n",
        "\n",
        "    Arguments:\n",
        "      boxes: A tensor of rank 2 or higher with a shape of `(..., num_boxes, 4)`\n",
        "        representing bounding boxes where each box is of the format\n",
        "        `[xmin, ymin, xmax, ymax]`.\n",
        "\n",
        "    Returns:\n",
        "      converted boxes with shape same as that of boxes.\n",
        "    \"\"\"\n",
        "    return tf.concat(\n",
        "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
        "        axis=-1,\n",
        "    )\n",
        "\n",
        "\n",
        "def convert_to_corners(boxes):\n",
        "    \"\"\"Changes the box format to corner coordinates\n",
        "\n",
        "    Arguments:\n",
        "      boxes: A tensor of rank 2 or higher with a shape of `(..., num_boxes, 4)`\n",
        "        representing bounding boxes where each box is of the format\n",
        "        `[x, y, width, height]`.\n",
        "\n",
        "    Returns:\n",
        "      converted boxes with shape same as that of boxes.\n",
        "    \"\"\"\n",
        "    return tf.concat(\n",
        "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
        "        axis=-1,\n",
        "    )\n",
        "def compute_iou(boxes1, boxes2):\n",
        "    \"\"\"Computes pairwise IOU matrix for given two sets of boxes\n",
        "\n",
        "    Arguments:\n",
        "      boxes1: A tensor with shape `(N, 4)` representing bounding boxes\n",
        "        where each box is of the format `[x, y, width, height]`.\n",
        "        boxes2: A tensor with shape `(M, 4)` representing bounding boxes\n",
        "        where each box is of the format `[x, y, width, height]`.\n",
        "\n",
        "    Returns:\n",
        "      pairwise IOU matrix with shape `(N, M)`, where the value at ith row\n",
        "        jth column holds the IOU between ith box and jth box from\n",
        "        boxes1 and boxes2 respectively.\n",
        "    \"\"\"\n",
        "    boxes1_corners = convert_to_corners(boxes1)\n",
        "    boxes2_corners = convert_to_corners(boxes2)\n",
        "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
        "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])\n",
        "    intersection = tf.maximum(0.0, rd - lu)\n",
        "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
        "    boxes1_area = boxes1[:, 2] * boxes1[:, 3]\n",
        "    boxes2_area = boxes2[:, 2] * boxes2[:, 3]\n",
        "    union_area = tf.maximum(\n",
        "        boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8\n",
        "    )\n",
        "    return tf.clip_by_value(intersection_area / union_area, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def visualize_detections(\n",
        "    image, boxes, classes, scores, figsize=(7, 7), linewidth=1, color=[0, 0, 1]\n",
        "):\n",
        "    \"\"\"Visualize Detections\"\"\"\n",
        "    image = np.array(image, dtype=np.uint8)\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(image)\n",
        "    ax = plt.gca()\n",
        "    for box, _cls, score in zip(boxes, classes, scores):\n",
        "        text = \"{}: {:.2f}\".format(_cls, score)\n",
        "        x1, y1, x2, y2 = box\n",
        "        w, h = x2 - x1, y2 - y1\n",
        "        patch = plt.Rectangle(\n",
        "            [x1, y1], w, h, fill=False, edgecolor=color, linewidth=linewidth\n",
        "        )\n",
        "        ax.add_patch(patch)\n",
        "        ax.text(\n",
        "            x1,\n",
        "            y1,\n",
        "            text,\n",
        "            bbox={\"facecolor\": color, \"alpha\": 0.4},\n",
        "            clip_box=ax.clipbox,\n",
        "            clip_on=True,\n",
        "        )\n",
        "    plt.show()\n",
        "    return ax\n",
        "class AnchorBox:\n",
        "    \"\"\"Generates anchor boxes.\n",
        "\n",
        "    This class has operations to generate anchor boxes for feature maps at\n",
        "    strides `[8, 16, 32, 64, 128]`. Where each anchor each box is of the\n",
        "    format `[x, y, width, height]`.\n",
        "\n",
        "    Attributes:\n",
        "      aspect_ratios: A list of float values representing the aspect ratios of\n",
        "        the anchor boxes at each location on the feature map\n",
        "      scales: A list of float values representing the scale of the anchor boxes\n",
        "        at each location on the feature map.\n",
        "      num_anchors: The number of anchor boxes at each location on feature map\n",
        "      areas: A list of float values representing the areas of the anchor\n",
        "        boxes for each feature map in the feature pyramid.\n",
        "      strides: A list of float value representing the strides for each feature\n",
        "        map in the feature pyramid.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.aspect_ratios = [0.5, 1.0, 2.0]\n",
        "        self.scales = [2 ** x for x in [0, 1 / 3, 2 / 3]]\n",
        "\n",
        "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
        "        self._strides = [2 ** i for i in range(3, 8)]\n",
        "        self._areas = [x ** 2 for x in [32.0, 64.0, 128.0, 256.0, 512.0]]\n",
        "        self._anchor_dims = self._compute_dims()\n",
        "\n",
        "    def _compute_dims(self):\n",
        "        \"\"\"Computes anchor box dimensions for all ratios and scales at all levels\n",
        "        of the feature pyramid.\n",
        "        \"\"\"\n",
        "        anchor_dims_all = []\n",
        "        for area in self._areas:\n",
        "            anchor_dims = []\n",
        "            for ratio in self.aspect_ratios:\n",
        "                anchor_height = tf.math.sqrt(area / ratio)\n",
        "                anchor_width = area / anchor_height\n",
        "                dims = tf.reshape(\n",
        "                    tf.stack([anchor_width, anchor_height], axis=-1), [1, 1, 2]\n",
        "                )\n",
        "                for scale in self.scales:\n",
        "                    anchor_dims.append(scale * dims)\n",
        "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
        "        return anchor_dims_all\n",
        "\n",
        "    def _get_anchors(self, feature_height, feature_width, level):\n",
        "        \"\"\"Generates anchor boxes for a given feature map size and level\n",
        "\n",
        "        Arguments:\n",
        "          feature_height: An integer representing the height of the feature map.\n",
        "          feature_width: An integer representing the width of the feature map.\n",
        "          level: An integer representing the level of the feature map in the\n",
        "            feature pyramid.\n",
        "\n",
        "        Returns:\n",
        "          anchor boxes with the shape\n",
        "          `(feature_height * feature_width * num_anchors, 4)`\n",
        "        \"\"\"\n",
        "        rx = tf.range(feature_width, dtype=tf.float32) + 0.5\n",
        "        ry = tf.range(feature_height, dtype=tf.float32) + 0.5\n",
        "        centers = tf.stack(tf.meshgrid(rx, ry), axis=-1) * self._strides[level - 3]\n",
        "        centers = tf.expand_dims(centers, axis=-2)\n",
        "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
        "        dims = tf.tile(\n",
        "            self._anchor_dims[level - 3], [feature_height, feature_width, 1, 1]\n",
        "        )\n",
        "        anchors = tf.concat([centers, dims], axis=-1)\n",
        "        return tf.reshape(\n",
        "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
        "        )\n",
        "\n",
        "    def get_anchors(self, image_height, image_width):\n",
        "        \"\"\"Generates anchor boxes for all the feature maps of the feature pyramid.\n",
        "\n",
        "        Arguments:\n",
        "          image_height: Height of the input image.\n",
        "          image_width: Width of the input image.\n",
        "\n",
        "        Returns:\n",
        "          anchor boxes for all the feature maps, stacked as a single tensor\n",
        "            with shape `(total_anchors, 4)`\n",
        "        \"\"\"\n",
        "        anchors = [\n",
        "            self._get_anchors(\n",
        "                tf.math.ceil(image_height / 2 ** i),\n",
        "                tf.math.ceil(image_width / 2 ** i),\n",
        "                i,\n",
        "            )\n",
        "            for i in range(3, 8)\n",
        "        ]\n",
        "        return tf.concat(anchors, axis=0)\n",
        "def random_flip_horizontal(image, boxes):\n",
        "    \"\"\"Flips image and boxes horizontally with 50% chance\n",
        "\n",
        "    Arguments:\n",
        "      image: A 3-D tensor of shape `(height, width, channels)` representing an\n",
        "        image.\n",
        "      boxes: A tensor with shape `(num_boxes, 4)` representing bounding boxes,\n",
        "        having normalized coordinates.\n",
        "\n",
        "    Returns:\n",
        "      Randomly flipped image and boxes\n",
        "    \"\"\"\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        boxes = tf.stack(\n",
        "            [1 - boxes[:, 2], boxes[:, 1], 1 - boxes[:, 0], boxes[:, 3]], axis=-1\n",
        "        )\n",
        "    return image, boxes\n",
        "\n",
        "\n",
        "def resize_and_pad_image(\n",
        "    image, min_side=800.0, max_side=1333.0, jitter=[640, 1024], stride=128.0\n",
        "):\n",
        "    \"\"\"Resizes and pads image while preserving aspect ratio.\n",
        "\n",
        "    1. Resizes images so that the shorter side is equal to `min_side`\n",
        "    2. If the longer side is greater than `max_side`, then resize the image\n",
        "      with longer side equal to `max_side`\n",
        "    3. Pad with zeros on right and bottom to make the image shape divisible by\n",
        "    `stride`\n",
        "\n",
        "    Arguments:\n",
        "      image: A 3-D tensor of shape `(height, width, channels)` representing an\n",
        "        image.\n",
        "      min_side: The shorter side of the image is resized to this value, if\n",
        "        `jitter` is set to None.\n",
        "      max_side: If the longer side of the image exceeds this value after\n",
        "        resizing, the image is resized such that the longer side now equals to\n",
        "        this value.\n",
        "      jitter: A list of floats containing minimum and maximum size for scale\n",
        "        jittering. If available, the shorter side of the image will be\n",
        "        resized to a random value in this range.\n",
        "      stride: The stride of the smallest feature map in the feature pyramid.\n",
        "        Can be calculated using `image_size / feature_map_size`.\n",
        "\n",
        "    Returns:\n",
        "      image: Resized and padded image.\n",
        "      image_shape: Shape of the image before padding.\n",
        "      ratio: The scaling factor used to resize the image\n",
        "    \"\"\"\n",
        "    image_shape = tf.cast(tf.shape(image)[:2], dtype=tf.float32)\n",
        "    if jitter is not None:\n",
        "        min_side = tf.random.uniform((), jitter[0], jitter[1], dtype=tf.float32)\n",
        "    ratio = min_side / tf.reduce_min(image_shape)\n",
        "    if ratio * tf.reduce_max(image_shape) > max_side:\n",
        "        ratio = max_side / tf.reduce_max(image_shape)\n",
        "    image_shape = ratio * image_shape\n",
        "    image = tf.image.resize(image, tf.cast(image_shape, dtype=tf.int32))\n",
        "    padded_image_shape = tf.cast(\n",
        "        tf.math.ceil(image_shape / stride) * stride, dtype=tf.int32\n",
        "    )\n",
        "    image = tf.image.pad_to_bounding_box(\n",
        "        image, 0, 0, padded_image_shape[0], padded_image_shape[1]\n",
        "    )\n",
        "    return image, image_shape, ratio\n",
        "\n",
        "\n",
        "def preprocess_data(sample):\n",
        "    \"\"\"Applies preprocessing step to a single sample\n",
        "\n",
        "    Arguments:\n",
        "      sample: A dict representing a single training sample.\n",
        "\n",
        "    Returns:\n",
        "      image: Resized and padded image with random horizontal flipping applied.\n",
        "      bbox: Bounding boxes with the shape `(num_objects, 4)` where each box is\n",
        "        of the format `[x, y, width, height]`.\n",
        "      class_id: An tensor representing the class id of the objects, having\n",
        "        shape `(num_objects,)`.\n",
        "    \"\"\"\n",
        "    image = sample[\"image\"]\n",
        "    bbox = swap_xy(sample[\"objects\"][\"bbox\"])\n",
        "    class_id = tf.cast(sample[\"objects\"][\"label\"], dtype=tf.int32)\n",
        "\n",
        "    image, bbox = random_flip_horizontal(image, bbox)\n",
        "    image, image_shape, _ = resize_and_pad_image(image)\n",
        "\n",
        "    bbox = tf.stack(\n",
        "        [\n",
        "            bbox[:, 0] * image_shape[1],\n",
        "            bbox[:, 1] * image_shape[0],\n",
        "            bbox[:, 2] * image_shape[1],\n",
        "            bbox[:, 3] * image_shape[0],\n",
        "        ],\n",
        "        axis=-1,\n",
        "    )\n",
        "    bbox = convert_to_xywh(bbox)\n",
        "    return image, bbox, class_id\n",
        "class LabelEncoder:\n",
        "    \"\"\"Transforms the raw labels into targets for training.\n",
        "\n",
        "    This class has operations to generate targets for a batch of samples which\n",
        "    is made up of the input images, bounding boxes for the objects present and\n",
        "    their class ids.\n",
        "\n",
        "    Attributes:\n",
        "      anchor_box: Anchor box generator to encode the bounding boxes.\n",
        "      box_variance: The scaling factors used to scale the bounding box targets.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._anchor_box = AnchorBox()\n",
        "        self._box_variance = tf.convert_to_tensor(\n",
        "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    def _match_anchor_boxes(\n",
        "        self, anchor_boxes, gt_boxes, match_iou=0.5, ignore_iou=0.4\n",
        "    ):\n",
        "        \"\"\"Matches ground truth boxes to anchor boxes based on IOU.\n",
        "\n",
        "        1. Calculates the pairwise IOU for the M `anchor_boxes` and N `gt_boxes`\n",
        "          to get a `(M, N)` shaped matrix.\n",
        "        2. The ground truth box with the maximum IOU in each row is assigned to\n",
        "          the anchor box provided the IOU is greater than `match_iou`.\n",
        "        3. If the maximum IOU in a row is less than `ignore_iou`, the anchor\n",
        "          box is assigned with the background class.\n",
        "        4. The remaining anchor boxes that do not have any class assigned are\n",
        "          ignored during training.\n",
        "\n",
        "        Arguments:\n",
        "          anchor_boxes: A float tensor with the shape `(total_anchors, 4)`\n",
        "            representing all the anchor boxes for a given input image shape,\n",
        "            where each anchor box is of the format `[x, y, width, height]`.\n",
        "          gt_boxes: A float tensor with shape `(num_objects, 4)` representing\n",
        "            the ground truth boxes, where each box is of the format\n",
        "            `[x, y, width, height]`.\n",
        "          match_iou: A float value representing the minimum IOU threshold for\n",
        "            determining if a ground truth box can be assigned to an anchor box.\n",
        "          ignore_iou: A float value representing the IOU threshold under which\n",
        "            an anchor box is assigned to the background class.\n",
        "\n",
        "        Returns:\n",
        "          matched_gt_idx: Index of the matched object\n",
        "          positive_mask: A mask for anchor boxes that have been assigned ground\n",
        "            truth boxes.\n",
        "          ignore_mask: A mask for anchor boxes that need to by ignored during\n",
        "            training\n",
        "        \"\"\"\n",
        "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
        "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
        "        matched_gt_idx = tf.argmax(iou_matrix, axis=1)\n",
        "        positive_mask = tf.greater_equal(max_iou, match_iou)\n",
        "        negative_mask = tf.less(max_iou, ignore_iou)\n",
        "        ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
        "        return (\n",
        "            matched_gt_idx,\n",
        "            tf.cast(positive_mask, dtype=tf.float32),\n",
        "            tf.cast(ignore_mask, dtype=tf.float32),\n",
        "        )\n",
        "\n",
        "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
        "        \"\"\"Transforms the ground truth boxes into targets for training\"\"\"\n",
        "        box_target = tf.concat(\n",
        "            [\n",
        "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
        "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:]),\n",
        "            ],\n",
        "            axis=-1,\n",
        "        )\n",
        "        box_target = box_target / self._box_variance\n",
        "        return box_target\n",
        "\n",
        "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):\n",
        "        \"\"\"Creates box and classification targets for a single sample\"\"\"\n",
        "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
        "        cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
        "        matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
        "            anchor_boxes, gt_boxes\n",
        "        )\n",
        "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
        "        box_target = self._compute_box_target(anchor_boxes, matched_gt_boxes)\n",
        "        matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
        "        cls_target = tf.where(\n",
        "            tf.not_equal(positive_mask, 1.0), -1.0, matched_gt_cls_ids\n",
        "        )\n",
        "        cls_target = tf.where(tf.equal(ignore_mask, 1.0), -2.0, cls_target)\n",
        "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
        "        label = tf.concat([box_target, cls_target], axis=-1)\n",
        "        return label\n",
        "\n",
        "    def encode_batch(self, batch_images, gt_boxes, cls_ids):\n",
        "        \"\"\"Creates box and classification targets for a batch\"\"\"\n",
        "        images_shape = tf.shape(batch_images)\n",
        "        batch_size = images_shape[0]\n",
        "\n",
        "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
        "        for i in range(batch_size):\n",
        "            label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
        "            labels = labels.write(i, label)\n",
        "        batch_images = tf.keras.applications.resnet.preprocess_input(batch_images)\n",
        "        return batch_images, labels.stack()\n",
        "def get_backbone():\n",
        "    \"\"\"Builds ResNet50 with pre-trained imagenet weights\"\"\"\n",
        "    backbone = keras.applications.ResNet50(\n",
        "        include_top=False, input_shape=[None, None, 3]\n",
        "    )\n",
        "    c3_output, c4_output, c5_output = [\n",
        "        backbone.get_layer(layer_name).output\n",
        "        for layer_name in [\"conv3_block4_out\", \"conv4_block6_out\", \"conv5_block3_out\"]\n",
        "    ]\n",
        "    return keras.Model(\n",
        "        inputs=[backbone.inputs], outputs=[c3_output, c4_output, c5_output]\n",
        "    )\n",
        "class FeaturePyramid(keras.layers.Layer):\n",
        "    \"\"\"Builds the Feature Pyramid with the feature maps from the backbone.\n",
        "\n",
        "    Attributes:\n",
        "      num_classes: Number of classes in the dataset.\n",
        "      backbone: The backbone to build the feature pyramid from.\n",
        "        Currently supports ResNet50 only.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, backbone=None, **kwargs):\n",
        "        super().__init__(name=\"FeaturePyramid\", **kwargs)\n",
        "        self.backbone = backbone if backbone else get_backbone()\n",
        "        self.conv_c3_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
        "        self.conv_c4_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
        "        self.conv_c5_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
        "        self.conv_c3_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
        "        self.conv_c4_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
        "        self.conv_c5_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
        "        self.conv_c6_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n",
        "        self.conv_c7_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n",
        "        self.upsample_2x = keras.layers.UpSampling2D(2)\n",
        "\n",
        "    def call(self, images, training=False):\n",
        "        c3_output, c4_output, c5_output = self.backbone(images, training=training)\n",
        "        p3_output = self.conv_c3_1x1(c3_output)\n",
        "        p4_output = self.conv_c4_1x1(c4_output)\n",
        "        p5_output = self.conv_c5_1x1(c5_output)\n",
        "        p4_output = p4_output + self.upsample_2x(p5_output)\n",
        "        p3_output = p3_output + self.upsample_2x(p4_output)\n",
        "        p3_output = self.conv_c3_3x3(p3_output)\n",
        "        p4_output = self.conv_c4_3x3(p4_output)\n",
        "        p5_output = self.conv_c5_3x3(p5_output)\n",
        "        p6_output = self.conv_c6_3x3(c5_output)\n",
        "        p7_output = self.conv_c7_3x3(tf.nn.relu(p6_output))\n",
        "        return p3_output, p4_output, p5_output, p6_output, p7_output\n",
        "\n",
        "def build_head(output_filters, bias_init):\n",
        "    \"\"\"Builds the class/box predictions head.\n",
        "\n",
        "    Arguments:\n",
        "      output_filters: Number of convolution filters in the final layer.\n",
        "      bias_init: Bias Initializer for the final convolution layer.\n",
        "\n",
        "    Returns:\n",
        "      A keras sequential model representing either the classification\n",
        "        or the box regression head depending on `output_filters`.\n",
        "    \"\"\"\n",
        "    head = keras.Sequential([keras.Input(shape=[None, None, 256])])\n",
        "    kernel_init = tf.initializers.RandomNormal(0.0, 0.01)\n",
        "    for _ in range(4):\n",
        "        head.add(\n",
        "            keras.layers.Conv2D(256, 3, padding=\"same\", kernel_initializer=kernel_init)\n",
        "        )\n",
        "        head.add(keras.layers.ReLU())\n",
        "    head.add(\n",
        "        keras.layers.Conv2D(\n",
        "            output_filters,\n",
        "            3,\n",
        "            1,\n",
        "            padding=\"same\",\n",
        "            kernel_initializer=kernel_init,\n",
        "            bias_initializer=bias_init,\n",
        "        )\n",
        "    )\n",
        "    return head\n",
        "\n",
        "class RetinaNet(keras.Model):\n",
        "    \"\"\"A subclassed Keras model implementing the RetinaNet architecture.\n",
        "\n",
        "    Attributes:\n",
        "      num_classes: Number of classes in the dataset.\n",
        "      backbone: The backbone to build the feature pyramid from.\n",
        "        Currently supports ResNet50 only.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, backbone=None, **kwargs):\n",
        "        super().__init__(name=\"RetinaNet\", **kwargs)\n",
        "        self.fpn = FeaturePyramid(backbone)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
        "        self.cls_head = build_head(9 * num_classes, prior_probability)\n",
        "        self.box_head = build_head(9 * 4, \"zeros\")\n",
        "\n",
        "    def call(self, image, training=False):\n",
        "        features = self.fpn(image, training=training)\n",
        "        N = tf.shape(image)[0]\n",
        "        cls_outputs = []\n",
        "        box_outputs = []\n",
        "        for feature in features:\n",
        "            box_outputs.append(tf.reshape(self.box_head(feature), [N, -1, 4]))\n",
        "            cls_outputs.append(\n",
        "                tf.reshape(self.cls_head(feature), [N, -1, self.num_classes])\n",
        "            )\n",
        "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
        "        box_outputs = tf.concat(box_outputs, axis=1)\n",
        "        return tf.concat([box_outputs, cls_outputs], axis=-1)\n",
        "\n",
        "class DecodePredictions(tf.keras.layers.Layer):\n",
        "    \"\"\"A Keras layer that decodes predictions of the RetinaNet model.\n",
        "\n",
        "    Attributes:\n",
        "      num_classes: Number of classes in the dataset\n",
        "      confidence_threshold: Minimum class probability, below which detections\n",
        "        are pruned.\n",
        "      nms_iou_threshold: IOU threshold for the NMS operation\n",
        "      max_detections_per_class: Maximum number of detections to retain per\n",
        "       class.\n",
        "      max_detections: Maximum number of detections to retain across all\n",
        "        classes.\n",
        "      box_variance: The scaling factors used to scale the bounding box\n",
        "        predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes=80,\n",
        "        confidence_threshold=0.05,\n",
        "        nms_iou_threshold=0.5,\n",
        "        max_detections_per_class=100,\n",
        "        max_detections=100,\n",
        "        box_variance=[0.1, 0.1, 0.2, 0.2],\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_classes = num_classes\n",
        "        self.confidence_threshold = confidence_threshold\n",
        "        self.nms_iou_threshold = nms_iou_threshold\n",
        "        self.max_detections_per_class = max_detections_per_class\n",
        "        self.max_detections = max_detections\n",
        "\n",
        "        self._anchor_box = AnchorBox()\n",
        "        self._box_variance = tf.convert_to_tensor(\n",
        "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    def _decode_box_predictions(self, anchor_boxes, box_predictions):\n",
        "        boxes = box_predictions * self._box_variance\n",
        "        boxes = tf.concat(\n",
        "            [\n",
        "                boxes[:, :, :2] * anchor_boxes[:, :, 2:] + anchor_boxes[:, :, :2],\n",
        "                tf.math.exp(boxes[:, :, 2:]) * anchor_boxes[:, :, 2:],\n",
        "            ],\n",
        "            axis=-1,\n",
        "        )\n",
        "        boxes_transformed = convert_to_corners(boxes)\n",
        "        return boxes_transformed\n",
        "\n",
        "    def call(self, images, predictions):\n",
        "        image_shape = tf.cast(tf.shape(images), dtype=tf.float32)\n",
        "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
        "        box_predictions = predictions[:, :, :4]\n",
        "        cls_predictions = tf.nn.sigmoid(predictions[:, :, 4:])\n",
        "        boxes = self._decode_box_predictions(anchor_boxes[None, ...], box_predictions)\n",
        "\n",
        "        return tf.image.combined_non_max_suppression(\n",
        "            tf.expand_dims(boxes, axis=2),\n",
        "            cls_predictions,\n",
        "            self.max_detections_per_class,\n",
        "            self.max_detections,\n",
        "            self.nms_iou_threshold,\n",
        "            self.confidence_threshold,\n",
        "            clip_boxes=False,\n",
        "        )\n",
        "\n",
        "class RetinaNetBoxLoss(tf.losses.Loss):\n",
        "    \"\"\"Implements Smooth L1 loss\"\"\"\n",
        "\n",
        "    def __init__(self, delta):\n",
        "        super().__init__(\n",
        "            reduction=\"none\", name=\"RetinaNetBoxLoss\"\n",
        "        )\n",
        "        self._delta = delta\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        difference = y_true - y_pred\n",
        "        absolute_difference = tf.abs(difference)\n",
        "        squared_difference = difference ** 2\n",
        "        loss = tf.where(\n",
        "            tf.less(absolute_difference, self._delta),\n",
        "            0.5 * squared_difference,\n",
        "            absolute_difference - 0.5,\n",
        "        )\n",
        "        return tf.reduce_sum(loss, axis=-1)\n",
        "\n",
        "\n",
        "class RetinaNetClassificationLoss(tf.losses.Loss):\n",
        "    \"\"\"Implements Focal loss\"\"\"\n",
        "\n",
        "    def __init__(self, alpha, gamma):\n",
        "        super().__init__(\n",
        "            reduction=\"none\", name=\"RetinaNetClassificationLoss\"\n",
        "        )\n",
        "        self._alpha = alpha\n",
        "        self._gamma = gamma\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            labels=y_true, logits=y_pred\n",
        "        )\n",
        "        probs = tf.nn.sigmoid(y_pred)\n",
        "        alpha = tf.where(tf.equal(y_true, 1.0), self._alpha, (1.0 - self._alpha))\n",
        "        pt = tf.where(tf.equal(y_true, 1.0), probs, 1 - probs)\n",
        "        loss = alpha * tf.pow(1.0 - pt, self._gamma) * cross_entropy\n",
        "        return tf.reduce_sum(loss, axis=-1)\n",
        "\n",
        "\n",
        "class RetinaNetLoss(tf.losses.Loss):\n",
        "    \"\"\"Wrapper to combine both the losses\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=80, alpha=0.25, gamma=2.0, delta=1.0):\n",
        "        super().__init__(reduction=\"auto\", name=\"RetinaNetLoss\")\n",
        "        self._clf_loss = RetinaNetClassificationLoss(alpha, gamma)\n",
        "        self._box_loss = RetinaNetBoxLoss(delta)\n",
        "        self._num_classes = num_classes\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "        box_labels = y_true[:, :, :4]\n",
        "        box_predictions = y_pred[:, :, :4]\n",
        "        cls_labels = tf.one_hot(\n",
        "            tf.cast(y_true[:, :, 4], dtype=tf.int32),\n",
        "            depth=self._num_classes,\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "        cls_predictions = y_pred[:, :, 4:]\n",
        "        positive_mask = tf.cast(tf.greater(y_true[:, :, 4], -1.0), dtype=tf.float32)\n",
        "        ignore_mask = tf.cast(tf.equal(y_true[:, :, 4], -2.0), dtype=tf.float32)\n",
        "        clf_loss = self._clf_loss(cls_labels, cls_predictions)\n",
        "        box_loss = self._box_loss(box_labels, box_predictions)\n",
        "        clf_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, clf_loss)\n",
        "        box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n",
        "        normalizer = tf.reduce_sum(positive_mask, axis=-1)\n",
        "        clf_loss = tf.math.divide_no_nan(tf.reduce_sum(clf_loss, axis=-1), normalizer)\n",
        "        box_loss = tf.math.divide_no_nan(tf.reduce_sum(box_loss, axis=-1), normalizer)\n",
        "        loss = clf_loss + box_loss\n",
        "        return loss\n",
        "model_dir = \"retinanet/\"\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "num_classes = 80\n",
        "batch_size = 2\n",
        "\n",
        "learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]\n",
        "learning_rate_boundaries = [125, 250, 500, 240000, 360000]\n",
        "learning_rate_fn = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries=learning_rate_boundaries, values=learning_rates\n",
        ")\n",
        "\n",
        "resnet50_backbone = get_backbone()\n",
        "loss_fn = RetinaNetLoss(num_classes)\n",
        "model = RetinaNet(num_classes, resnet50_backbone)\n",
        "\n",
        "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate_fn, momentum=0.9)\n",
        "model.compile(loss=loss_fn, optimizer=optimizer)\n",
        "\n",
        "callbacks_list = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(model_dir, \"weights\" + \"_epoch_{epoch}\"),\n",
        "        monitor=\"loss\",\n",
        "        save_best_only=False,\n",
        "        save_weights_only=True,\n",
        "        verbose=1,\n",
        "    )\n",
        "]\n",
        "#  set `data_dir=None` to load the complete dataset\n",
        "\n",
        "(train_dataset, val_dataset), dataset_info = tfds.load(\n",
        "    \"coco/2017\", split=[\"train\", \"validation\"], with_info=True, data_dir=\"data\"\n",
        ")\n",
        "\n",
        "autotune = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
        "train_dataset = train_dataset.shuffle(8 * batch_size)\n",
        "train_dataset = train_dataset.padded_batch(\n",
        "    batch_size=batch_size, padding_values=(0.0, 1e-8, -1), drop_remainder=True\n",
        ")\n",
        "train_dataset = train_dataset.map(\n",
        "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
        ")\n",
        "train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())\n",
        "train_dataset = train_dataset.prefetch(autotune)\n",
        "\n",
        "val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
        "val_dataset = val_dataset.padded_batch(\n",
        "    batch_size=1, padding_values=(0.0, 1e-8, -1), drop_remainder=True\n",
        ")\n",
        "val_dataset = val_dataset.map(label_encoder.encode_batch, num_parallel_calls=autotune)\n",
        "val_dataset = val_dataset.apply(tf.data.experimental.ignore_errors())\n",
        "val_dataset = val_dataset.prefetch(autotune)\n",
        "# Uncomment the following lines, when training on full dataset\n",
        "# train_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // batch_size\n",
        "# val_steps_per_epoch = \\\n",
        "#     dataset_info.splits[\"validation\"].num_examples // batch_size\n",
        "\n",
        "# train_steps = 4 * 100000\n",
        "# epochs = train_steps // train_steps_per_epoch\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "# Running 100 training and 50 validation steps,\n",
        "# remove `.take` when training on the full dataset\n",
        "\n",
        "model.fit(\n",
        "    train_dataset.take(100),\n",
        "    validation_data=val_dataset.take(50),\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1,\n",
        ")\n",
        "# Change this to `model_dir` when not using the downloaded weights\n",
        "weights_dir = \"data\"\n",
        "\n",
        "latest_checkpoint = tf.train.latest_checkpoint(weights_dir)\n",
        "model.load_weights(latest_checkpoint)\n",
        "image = tf.keras.Input(shape=[None, None, 3], name=\"image\")\n",
        "predictions = model(image, training=False)\n",
        "detections = DecodePredictions(confidence_threshold=0.5)(image, predictions)\n",
        "inference_model = tf.keras.Model(inputs=image, outputs=detections)\n",
        "def prepare_image(image):\n",
        "    image, _, ratio = resize_and_pad_image(image, jitter=None)\n",
        "    image = tf.keras.applications.resnet.preprocess_input(image)\n",
        "    return tf.expand_dims(image, axis=0), ratio\n",
        "\n",
        "\n",
        "val_dataset = tfds.load(\"coco/2017\", split=\"validation\", data_dir=\"data\")\n",
        "int2str = dataset_info.features[\"objects\"][\"label\"].int2str\n",
        "\n",
        "for sample in val_dataset.take(2):\n",
        "    image = tf.cast(sample[\"image\"], dtype=tf.float32)\n",
        "    input_image, ratio = prepare_image(image)\n",
        "    detections = inference_model.predict(input_image)\n",
        "    num_detections = detections.valid_detections[0]\n",
        "    class_names = [\n",
        "        int2str(int(x)) for x in detections.nmsed_classes[0][:num_detections]\n",
        "    ]\n",
        "    visualize_detections(\n",
        "        image,\n",
        "        detections.nmsed_boxes[0][:num_detections] / ratio,\n",
        "        class_names,\n",
        "        detections.nmsed_scores[0][:num_detections],\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NY3JrPsvZ9x",
        "outputId": "9dee2ce0-0232-45ea-d050-5e873661d2ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3/Unknown - 260s 75s/step - loss: 3.9827"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Recommender Systems with Explicit Feedback\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate some sample explicit feedback data\n",
        "num_users = 100\n",
        "num_items = 50\n",
        "latent_dim = 10\n",
        "ratings = np.random.randint(1, 6, size=(num_users, num_items))  # User ratings (1-5)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a matrix factorization model using TensorFlow\n",
        "user_input = tf.keras.layers.Input(shape=(1,))\n",
        "item_input = tf.keras.layers.Input(shape=(1,))\n",
        "user_embedding = tf.keras.layers.Embedding(num_users, latent_dim)(user_input)\n",
        "item_embedding = tf.keras.layers.Embedding(num_items, latent_dim)(item_input)\n",
        "output = tf.keras.layers.Dot(axes=2)([user_embedding, item_embedding])\n",
        "\n",
        "model = tf.keras.models.Model(inputs=[user_input, item_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "user_indices, item_indices = np.where(train_ratings > 0)\n",
        "train_users = user_indices.tolist()\n",
        "train_items = item_indices.tolist()\n",
        "train_ratings = train_ratings[user_indices, item_indices]\n",
        "\n",
        "model.fit([np.array(train_users), np.array(train_items)], np.array(train_ratings), epochs=10, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_user_indices, test_item_indices = np.where(test_ratings > 0)\n",
        "test_users = test_user_indices.tolist()\n",
        "test_items = test_item_indices.tolist()\n",
        "test_ratings = test_ratings[test_user_indices, test_item_indices]\n",
        "\n",
        "predicted_ratings = model.predict([np.array(test_users), np.array(test_items)])\n",
        "predicted_ratings = np.squeeze(predicted_ratings, axis=(1, 2))  # Reshape for MSE calculation\n",
        "\n",
        "mse = mean_squared_error(test_ratings, predicted_ratings)\n",
        "print(f'Mean Squared Error on Test Data: {mse}')\n"
      ],
      "metadata": {
        "id": "shwLweU33F6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropagation in Neural Networks using Numpy\n",
        "import numpy as np\n",
        "\n",
        "# Define the neural network architecture\n",
        "input_size = 2\n",
        "hidden_size = 4\n",
        "output_size = 1\n",
        "learning_rate = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "# Generate some sample data\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Initialize weights and biases\n",
        "np.random.seed(0)\n",
        "w1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "w2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, w1) + b1\n",
        "    a1 = 1 / (1 + np.exp(-z1))\n",
        "    z2 = np.dot(a1, w2) + b2\n",
        "    a2 = z2  # Linear activation for regression\n",
        "\n",
        "    # Calculate loss (MSE)\n",
        "    loss = np.mean((a2 - y) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    dz2 = a2 - y\n",
        "    dw2 = np.dot(a1.T, dz2)\n",
        "    db2 = np.sum(dz2, axis=0)\n",
        "    dz1 = np.dot(dz2, w2.T) * (a1 * (1 - a1))\n",
        "    dw1 = np.dot(X.T, dz1)\n",
        "    db1 = np.sum(dz1, axis=0)\n",
        "\n",
        "    # Update weights and biases\n",
        "    w1 -= learning_rate * dw1\n",
        "    b1 -= learning_rate * db1\n",
        "    w2 -= learning_rate * dw2\n",
        "    b2 -= learning_rate * db2\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "# After training, you can use the trained model for prediction\n",
        "z1 = np.dot(X, w1) + b1\n",
        "a1 = 1 / (1 + np.exp(-z1))\n",
        "z2 = np.dot(a1, w2) + b2\n",
        "predictions = z2\n",
        "\n",
        "print(\"Predictions:\")\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "Zr5Bi3DV6RyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CgYVgTub7Jm5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}